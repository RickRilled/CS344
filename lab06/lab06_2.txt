Entropy(H) = - [(1/2)lg(1/2) + (1/2)lg(1/2)] = - (-1) = 1

R(A) = 7/12*Entropy(Hungry) + 5/12*Entropy(-Hungry)

    = -(7/12((2/7)lg(2/7) + (5/7)lg(5/7))) + -(5/12((1/5)lg(1/5) + (4/5)lg(4/5)))

    = 0.804

Information Gain = E(H) - R(A) = 1 - 0.804 = 0.196

This did not provide as much information gain as the examples in class, namly patron. That is the better question to be asking.