{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Homework 02 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Royce Lloyd, 3/8/2019, CS344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A higher number means spam, a lower number means ham.\nThe probability of these words being spam, based on the spam and ham corpus, are: \n {'do': 0.3333333333333333, 'i': 0.01, 'like': 0.3333333333333333, 'green': 0.01, 'eggs': 0.01, 'and': 0.01, 'ham': 0.01, 'I': 0.99, 'am': 0.99, 'spam': 0.99, 'not': 0.99, 'that': 0.99, 'spamiam': 0.99}\nThe probability of the email, gives the contents of emailContents, is spam, is:  0.19999999999999918\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This module will create a sam filter based on Paul Graham’s A Plan for Spam.\n",
    "\n",
    "Written by Royce Lloyd for CS 344 at Calvin College\n",
    "3/8/2019\n",
    "\"\"\"\n",
    "\n",
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "\n",
    "ngood = len(spam_corpus)\n",
    "nbad = len(ham_corpus)\n",
    "\n",
    "emailContents = [\"save\", \"on\", \"green\", \"eggs\", \"and\", \"spam\", \"do\", \"you\", \"like\", \"spam\", \"80\", \"$\", \"off\", \"click\",\n",
    "                 \"here\", \"am\", \"I\", \"spamiam\", \"ham\", \"that\", \"i\"]\n",
    "\n",
    "def getprob(wordInQuestion):\n",
    "\n",
    "    #Check for KeyErrors(Out of range of dict)\n",
    "    try:\n",
    "        g = (2 * goodHash[wordInQuestion])\n",
    "    except KeyError:\n",
    "        g = 0\n",
    "\n",
    "    try:\n",
    "        b = badHash[wordInQuestion]\n",
    "    except KeyError:\n",
    "        b = 0\n",
    "\n",
    "    #Computer the possibility of spam\n",
    "    if g + b > 0:\n",
    "        return max(0.01, min(0.99, min(1.0, b/nbad) / (min(1.0, g/ngood) + min(1.0, b/nbad))))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def isSpam(li):\n",
    "\n",
    "    #Find prod\n",
    "    prod = 1\n",
    "    for value in li:\n",
    "        prod = prod * value\n",
    "\n",
    "    #Create a list f compliments\n",
    "    complList = []\n",
    "    for value in li:\n",
    "        complList.append(1 - value)\n",
    "\n",
    "    #Computer the product of those compliments\n",
    "    compProd = 1\n",
    "    for value in complList:\n",
    "        compProd = compProd * value\n",
    "\n",
    "    #Return the probability of the email being spam\n",
    "    return prod / (prod + (compProd))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This section takes our corpus(s) and creates a single list of tokens.\n",
    "\n",
    "Big thank you to Alex Martelli on StackOverflow for lines 55-61\n",
    "https://stackoverflow.com/questions/952914/how-to-make-a-flat-list-out-of-list-of-lists\n",
    "\"\"\"\n",
    "spamWords = []\n",
    "hamWords = []\n",
    "\n",
    "for sublist in spam_corpus:\n",
    "    for item in sublist:\n",
    "        spamWords.append(item)\n",
    "\n",
    "for sublist in ham_corpus:\n",
    "    for item in sublist:\n",
    "        hamWords.append(item)\n",
    "\n",
    "\"\"\"\n",
    "Create a hash table(dictionary) for the number of times each word appears in the good and bad corpus\n",
    "\"\"\"\n",
    "goodHash = {}\n",
    "badHash = {}\n",
    "\n",
    "for word in hamWords:\n",
    "    goodCount = 0\n",
    "    for checkWord in hamWords:\n",
    "        if word == checkWord:\n",
    "            goodCount += 1\n",
    "    goodHash[word] = goodCount\n",
    "\n",
    "\n",
    "for word in spamWords:\n",
    "    badCount = 0\n",
    "    for checkWord in spamWords:\n",
    "        if word == checkWord:\n",
    "            badCount += 1\n",
    "    badHash[word] = badCount\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Use the function getprob to determine the possibility that an email containing these words\n",
    "is spam or not.\n",
    "\"\"\"\n",
    "hashTotal = {}\n",
    "\n",
    "for word in goodHash:\n",
    "    hashTotal[word] = getprob(word)\n",
    "\n",
    "for word in badHash:\n",
    "    hashTotal[word] = getprob(word)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Create a list of probabilities from emailContents.\n",
    "These probabilities are the chances of that word being used in a spam email,\n",
    "based on our corpus.\n",
    "\"\"\"\n",
    "probsTemp = {}\n",
    "probs = []\n",
    "\n",
    "for word in emailContents:\n",
    "    probsTemp[word] = getprob(word)\n",
    "\n",
    "for key in probsTemp:\n",
    "    if probsTemp[key] != 0:\n",
    "        probs.append(probsTemp[key])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"A higher number means spam, a lower number means ham.\")\n",
    "print(\"The probability of these words being spam, based on the spam and ham corpus, are:\", \"\\n\", hashTotal)\n",
    "# print(probsTemp)\n",
    "# print(probs)\n",
    "print(\"The probability of the email, gives the contents of emailContents, is spam, is: \", isSpam(probs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Bayesian approach because you are essentialy calculating the condition probability of an email being spam, given what you already know about the possibility of that word being spam. Grahm could create a Bayesian Network which describes how a word affects an emails chances of being spam. Your independat values would be the word itself. It would be directly connected to the email and have a probability calculated for it's chances of being spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False: 0.9, True: 0.1\nFalse: 0.952, True: 0.0476\nFalse: 0.01, True: 0.99\nFalse: 0.639, True: 0.361\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This module will compute a list of probabilities based on the Bayesian Network from Figure 14.12a\n",
    "\n",
    "An extension of this exercise, meaning part 2b-d(handCalculations),\n",
    "can be found in paper at the office of Prof. VanderLinden\n",
    "\n",
    "Written by Royce Lloyd for CS344 at Calvin College\n",
    "3/8/2019\n",
    "\"\"\"\n",
    "\n",
    "from probability import BayesNet, enumeration_ask, elimination_ask, gibbs_ask\n",
    "\n",
    "\n",
    "T, F = True, False\n",
    "\n",
    "cloudy = BayesNet([\n",
    "    ('Cloudy', '', 0.5),\n",
    "    ('Sprinkler', 'Cloudy', {T: .10, F: .50}),\n",
    "    ('Rain', 'Cloudy', {T: .80, F: .20}),\n",
    "    ('WetGrass', 'Sprinkler Rain', {(T, T): .99, (T, F): .90, (F, T): .90, (F, F): .00})\n",
    "])\n",
    "\n",
    "#P(Sprinker | cloudy)\n",
    "print(enumeration_ask('Sprinkler', dict(Cloudy=T), cloudy).show_approx())\n",
    "\n",
    "#P(Cloudy| the sprinkler is running and it’s not raining)\n",
    "print(enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=F), cloudy).show_approx())\n",
    "\n",
    "#P(WetGrass | it’s cloudy, the sprinkler is running and it’s raining)\n",
    "print(enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), cloudy).show_approx())\n",
    "\n",
    "#P(Cloudy | the grass is not wet)\n",
    "print(enumeration_ask('Cloudy', dict(WetGrass=F), cloudy).show_approx())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
